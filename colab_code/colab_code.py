# -*- coding: utf-8 -*-
"""final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lFKi9MiD-_DMIa8jIbo-FERe_tvQt5_s

# Libraries and Tools
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.stats import norm,skew
from sklearn.preprocessing import StandardScaler
from scipy import stats

"""#  Data Loading and Initial Exploration"""

dataset = pd.read_csv('/content/drive/MyDrive/flights_sample_3m.csv')

dataset.head()

dataset.tail()

dataset.columns

dataset.describe()

dataset.shape

dataset.isnull().sum()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# calculate correlation
corr = dataset.corr(numeric_only=True)

# show as heatmap
plt.figure(figsize=(12,8))
sns.heatmap(corr, annot=True, cmap="coolwarm", fmt=".2f")
plt.show()

corr['ARR_DELAY'].sort_values(ascending=False)

"""# Data Preprocessing

Target Leakage Prevention
"""

dataset = dataset.drop(columns=['DEP_DELAY','DEP_TIME','ARR_TIME',])

dataset.columns

"""Target Leakage Prevention"""

dataset = dataset.drop(columns=['TAXI_OUT','TAXI_IN','WHEELS_OFF','WHEELS_ON','ELAPSED_TIME','AIR_TIME'])

"""Delay Cause Variables"""

dataset = dataset.drop(columns=["DELAY_DUE_CARRIER", "DELAY_DUE_WEATHER", "DELAY_DUE_NAS", "DELAY_DUE_SECURITY", "DELAY_DUE_LATE_AIRCRAFT"])

"""Redundant/Non-Predictive Features"""

dataset = dataset.drop(columns=['CANCELLED','CANCELLATION_CODE','DIVERTED','DOT_CODE','AIRLINE','AIRLINE_DOT','ORIGIN_CITY','DEST_CITY'])

dataset.columns

dataset.shape

"""# Missing Value Handling"""

dataset.isnull().sum()

(dataset.isnull().sum() / len(dataset)) * 100

dataset = dataset.dropna().reset_index(drop=True)

(dataset.isnull().sum() / len(dataset)) * 100

dataset.shape

dataset.info()

"""# Feature Engineering

Target Variable Creation
"""

dataset['DELAYED'] = dataset['ARR_DELAY'].apply(lambda x: 1 if x > 15 else 0)

dataset.info()

# Convert FL_DATE to datetime
dataset['FL_DATE'] = pd.to_datetime(dataset['FL_DATE'])

# Extract day of week (0 = Monday, 6 = Sunday)
dataset['DAY_OF_WEEK'] = dataset['FL_DATE'].dt.dayofweek

# Extract month (1–12)
dataset['MONTH'] = dataset['FL_DATE'].dt.month

# Is weekend? (Saturday=5, Sunday=6)
dataset['IS_WEEKEND'] = dataset['DAY_OF_WEEK'].apply(lambda x: 1 if x >= 5 else 0)

# Convert CRS_DEP_TIME to string with zero padding (e.g., 540 → "0540")
dataset['CRS_DEP_TIME_STR'] = dataset['CRS_DEP_TIME'].astype(str).str.zfill(4)

# Extract hour
dataset['DEP_HOUR'] = dataset['CRS_DEP_TIME_STR'].str[:2].astype(int)

# Create time block: morning/afternoon/night
def time_block(hour):
    if 5 <= hour < 12:
        return 'morning'
    elif 12 <= hour < 17:
        return 'afternoon'
    elif 17 <= hour < 21:
        return 'evening'
    else:
        return 'night'

dataset['TIME_BLOCK'] = dataset['DEP_HOUR'].apply(time_block)

def distance_category(distance):
    if distance < 500:
        return 'short'
    elif 500 <= distance < 1500:
        return 'medium'
    else:
        return 'long'

dataset['DISTANCE_CAT'] = dataset['DISTANCE'].apply(distance_category)

"""# Encoding Categorical Variables"""

from sklearn.preprocessing import LabelEncoder

categorical_columns = ['AIRLINE_CODE', 'ORIGIN', 'DEST', 'TIME_BLOCK', 'DISTANCE_CAT']

label_encoders = {}
for col in categorical_columns:
    le = LabelEncoder()
    dataset[col] = le.fit_transform(dataset[col])
    label_encoders[col] = le  # store encoders for later use

"""# Feature Scaling"""

from sklearn.preprocessing import StandardScaler

numeric_columns = ['CRS_ELAPSED_TIME', 'DISTANCE', 'CRS_DEP_TIME', 'DEP_HOUR']

scaler = StandardScaler()
dataset[numeric_columns] = scaler.fit_transform(dataset[numeric_columns])

dataset.info()

"""# Train-Test Split"""

from sklearn.model_selection import train_test_split

# Features and target
X = dataset.drop(['ARR_DELAY', 'DELAYED', 'FL_DATE', 'CRS_DEP_TIME_STR'], axis=1)
y = dataset['DELAYED']

# Train/test split (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)

"""# XGBoost Classifier"""

import time
import xgboost as xgb
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, roc_curve
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np

# --- Step 1: Calculate class distribution ---
class_counts = y_train.value_counts()
base_weight = class_counts[0] / class_counts[1]
print(f"Class distribution in training set:")
print(f"Class 0 (on-time): {class_counts[0]}")
print(f"Class 1 (delayed): {class_counts[1]}")
print(f"Imbalance ratio: {base_weight:.2f}")
print("="*60)

# --- Step 2: Train model with optimized parameters ---
start_time = time.time()
xgb_model = xgb.XGBClassifier(
    n_estimators=300,              # Increased for better learning
    max_depth=8,                   # Deeper trees for complex patterns
    learning_rate=0.08,            # Balanced learning rate
    min_child_weight=1,            # Allow more granular splits
    gamma=0.2,                     # Regularization for overfitting
    subsample=0.85,                # Use 85% of data per tree
    colsample_bytree=0.85,         # Use 85% of features per tree
    colsample_bylevel=0.85,        # Additional feature sampling per level
    reg_alpha=0.1,                 # L1 regularization
    reg_lambda=1.5,                # L2 regularization (increased)
    scale_pos_weight=base_weight * 0.7,  # Adjusted weight for better balance
    max_delta_step=1,              # Helps with imbalanced classes
    use_label_encoder=False,
    eval_metric="logloss",
    tree_method="hist",
    n_jobs=-1,
    random_state=42
)

print("Training optimized XGBoost model...")
xgb_model.fit(X_train, y_train)
end_time = time.time()
training_time = end_time - start_time
print(f"Training completed in {training_time:.2f} seconds ({training_time/60:.2f} minutes)")
print("="*60)

# --- Step 3: Find optimal threshold for accuracy ---
y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]

# Test multiple thresholds with finer granularity
thresholds = np.arange(0.35, 0.65, 0.02)
best_threshold = 0.5
best_accuracy = 0
best_f1 = 0

print("\nTesting different prediction thresholds:")
print(f"{'Threshold':<12} {'Accuracy':<12} {'Precision':<12} {'Recall':<12} {'F1-Score':<12}")
print("-" * 65)

for threshold in thresholds:
    y_pred_temp = (y_pred_proba >= threshold).astype(int)
    acc = accuracy_score(y_test, y_pred_temp)
    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_temp).ravel()

    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

    print(f"{threshold:.2f}         {acc:.4f}       {precision:.4f}       {recall:.4f}       {f1:.4f}")

    # Find threshold with best accuracy (with F1 as tiebreaker)
    if acc > best_accuracy or (acc == best_accuracy and f1 > best_f1):
        best_accuracy = acc
        best_f1 = f1
        best_threshold = threshold

print(f"\nBest threshold: {best_threshold:.2f} (Accuracy: {best_accuracy:.4f}, F1-Score: {best_f1:.4f})")
print("="*60)

# --- Step 4: Make predictions with optimal threshold ---
y_pred_xgb = (y_pred_proba >= best_threshold).astype(int)

# --- Step 5: Evaluation metrics ---
print("\nFINAL MODEL PERFORMANCE:")
print("="*60)
print(f"Accuracy: {accuracy_score(y_test, y_pred_xgb):.4f}")
print(f"ROC-AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}")

precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)
pr_auc = auc(recall, precision)
print(f"Precision-Recall AUC: {pr_auc:.4f}")

print("\nClassification Report:")
print(classification_report(y_test, y_pred_xgb))

# Detailed metrics for delayed flights
cm_xgb = confusion_matrix(y_test, y_pred_xgb)
tn, fp, fn, tp = cm_xgb.ravel()
recall_delayed = tp / (tp + fn)
precision_delayed = tp / (tp + fp) if (tp + fp) > 0 else 0
f1_delayed = 2 * (precision_delayed * recall_delayed) / (precision_delayed + recall_delayed)

print("\nDETAILED METRICS FOR DELAYED FLIGHTS (Class 1):")
print("="*60)
print(f"True Positives (correctly predicted delays): {tp}")
print(f"False Positives (false alarms): {fp}")
print(f"False Negatives (missed delays): {fn}")
print(f"True Negatives (correctly predicted on-time): {tn}")
print(f"\nRecall: {recall_delayed:.4f} → Catching {recall_delayed*100:.2f}% of actual delays")
print(f"Precision: {precision_delayed:.4f} → {precision_delayed*100:.2f}% of delay predictions are correct")
print(f"F1-Score: {f1_delayed:.4f}")

# --- Step 6: Visualizations ---
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# Confusion Matrix
sns.heatmap(cm_xgb, annot=True, fmt="d", cmap="Blues", ax=axes[0, 0])
axes[0, 0].set_title(f"Confusion Matrix (Threshold: {best_threshold:.2f})")
axes[0, 0].set_xlabel("Predicted")
axes[0, 0].set_ylabel("Actual")

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
axes[0, 1].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc_score(y_test, y_pred_proba):.2f})')
axes[0, 1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')
axes[0, 1].set_xlabel('False Positive Rate')
axes[0, 1].set_ylabel('True Positive Rate')
axes[0, 1].set_title('ROC Curve')
axes[0, 1].legend(loc="lower right")
axes[0, 1].grid(True, alpha=0.3)

# Precision-Recall Curve
precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_proba)
axes[1, 0].plot(recall_curve, precision_curve, color='green', lw=2, label=f'PR curve (AUC = {pr_auc:.2f})')
axes[1, 0].set_xlabel('Recall')
axes[1, 0].set_ylabel('Precision')
axes[1, 0].set_title('Precision-Recall Curve')
axes[1, 0].legend(loc="lower left")
axes[1, 0].grid(True, alpha=0.3)

# Feature Importance (Top 15)
xgb_importance = pd.Series(xgb_model.feature_importances_, index=X.columns).sort_values(ascending=False)
xgb_importance.head(15).plot(kind="barh", ax=axes[1, 1], color="lightcoral")
axes[1, 1].set_title("Top 15 Most Important Features")
axes[1, 1].set_xlabel("Importance Score")
axes[1, 1].invert_yaxis()

plt.tight_layout()
plt.show()

# --- Step 7: Summary ---
print("\n" + "="*60)
print("SUMMARY & RECOMMENDATIONS:")
print("="*60)
print(f"✓ Model is catching {recall_delayed*100:.1f}% of delays")
print(f"✓ {precision_delayed*100:.1f}% of delay predictions are accurate")
print(f"✓ Overall accuracy: {accuracy_score(y_test, y_pred_xgb)*100:.1f}%")
print(f"✓ Best performing threshold: {best_threshold:.2f}")


print("="*60)

"""# Logistic Regression"""

import time
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, roc_curve
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

print("="*60)
print("LOGISTIC REGRESSION FOR FLIGHT DELAY PREDICTION")
print("="*60)

# --- Step 1: Check class distribution ---
class_counts = y_train.value_counts()
print(f"\nClass distribution in training set:")
print(f"Class 0 (on-time): {class_counts[0]:,}")
print(f"Class 1 (delayed): {class_counts[1]:,}")
print(f"Imbalance ratio: {class_counts[0]/class_counts[1]:.2f}:1")
print("="*60)

# --- Step 2: Feature Scaling (important for Logistic Regression) ---
print("\nScaling features...")
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
print("✓ Feature scaling completed")

# --- Step 3: Train Logistic Regression ---
print("\nTraining Logistic Regression model...")
start_time = time.time()

log_model = LogisticRegression(
    class_weight='balanced',    # Automatically handles class imbalance
    max_iter=1000,              # Maximum iterations
    solver='saga',              # Best for large datasets, supports L1/L2
    penalty='l2',               # L2 regularization (prevents overfitting)
    C=1.0,                      # Regularization strength (lower = more regularization)
    n_jobs=-1,                  # Use all CPU cores
    random_state=42,
    verbose=0
)

log_model.fit(X_train_scaled, y_train)

end_time = time.time()
training_time = end_time - start_time
print(f"✓ Training completed in {training_time:.2f} seconds ({training_time/60:.2f} minutes)")
print("="*60)

# --- Step 4: Get prediction probabilities ---
print("\nGenerating predictions...")
y_pred_proba = log_model.predict_proba(X_test_scaled)[:, 1]

# --- Step 5: Find optimal threshold ---
thresholds = np.arange(0.3, 0.6, 0.05)
best_threshold = 0.5
best_f1 = 0

print("\nTesting different prediction thresholds:")
print(f"{'Threshold':<12} {'Precision':<12} {'Recall':<12} {'F1-Score':<12}")
print("-" * 50)

for threshold in thresholds:
    y_pred_temp = (y_pred_proba >= threshold).astype(int)
    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_temp).ravel()

    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

    print(f"{threshold:.2f}         {precision:.4f}       {recall:.4f}       {f1:.4f}")

    if f1 > best_f1:
        best_f1 = f1
        best_threshold = threshold

print(f"\n✓ Best threshold: {best_threshold:.2f} (F1-Score: {best_f1:.4f})")
print("="*60)

# --- Step 6: Make final predictions ---
y_pred_log = (y_pred_proba >= best_threshold).astype(int)

# --- Step 7: Evaluation Metrics ---
print("\nFINAL MODEL PERFORMANCE:")
print("="*60)
print(f"Accuracy: {accuracy_score(y_test, y_pred_log):.4f}")
print(f"ROC-AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}")

precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)
pr_auc = auc(recall, precision)
print(f"Precision-Recall AUC: {pr_auc:.4f}")

print("\nClassification Report:")
print(classification_report(y_test, y_pred_log))

# Confusion matrix
cm_log = confusion_matrix(y_test, y_pred_log)
tn, fp, fn, tp = cm_log.ravel()

# Detailed metrics
recall_delayed = tp / (tp + fn)
precision_delayed = tp / (tp + fp) if (tp + fp) > 0 else 0
f1_delayed = 2 * (precision_delayed * recall_delayed) / (precision_delayed + recall_delayed)

print("\nDETAILED METRICS FOR DELAYED FLIGHTS (Class 1):")
print("="*60)
print(f"True Positives (correctly predicted delays): {tp:,}")
print(f"False Positives (false alarms): {fp:,}")
print(f"False Negatives (missed delays): {fn:,}")
print(f"True Negatives (correctly predicted on-time): {tn:,}")
print(f"\nRecall: {recall_delayed:.4f} → Catching {recall_delayed*100:.2f}% of actual delays")
print(f"Precision: {precision_delayed:.4f} → {precision_delayed*100:.2f}% of delay predictions are correct")
print(f"F1-Score: {f1_delayed:.4f}")

# --- Step 8: Feature Coefficients (Feature Importance) ---
feature_importance = pd.DataFrame({
    'Feature': X.columns,
    'Coefficient': log_model.coef_[0],
    'Abs_Coefficient': np.abs(log_model.coef_[0])
}).sort_values('Abs_Coefficient', ascending=False)

print("\nTop 10 Most Important Features:")
print("="*60)
for idx, row in feature_importance.head(10).iterrows():
    direction = "increases" if row['Coefficient'] > 0 else "decreases"
    print(f"{row['Feature']:<20} {row['Coefficient']:>8.4f} ({direction} delay probability)")

# --- Step 9: Visualizations ---
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# Confusion Matrix
sns.heatmap(cm_log, annot=True, fmt=",d", cmap="Purples", ax=axes[0, 0])
axes[0, 0].set_title(f"Confusion Matrix (Threshold: {best_threshold:.2f})")
axes[0, 0].set_xlabel("Predicted")
axes[0, 0].set_ylabel("Actual")

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
roc_auc = roc_auc_score(y_test, y_pred_proba)
axes[0, 1].plot(fpr, tpr, color='purple', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
axes[0, 1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')
axes[0, 1].set_xlabel('False Positive Rate')
axes[0, 1].set_ylabel('True Positive Rate')
axes[0, 1].set_title('ROC Curve')
axes[0, 1].legend(loc="lower right")
axes[0, 1].grid(True, alpha=0.3)

# Precision-Recall Curve
precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_proba)
axes[1, 0].plot(recall_curve, precision_curve, color='darkviolet', lw=2, label=f'PR curve (AUC = {pr_auc:.2f})')
axes[1, 0].set_xlabel('Recall')
axes[1, 0].set_ylabel('Precision')
axes[1, 0].set_title('Precision-Recall Curve')
axes[1, 0].legend(loc="lower left")
axes[1, 0].grid(True, alpha=0.3)

# Feature Importance (Top 15)
top_features = feature_importance.head(15)
colors = ['red' if x < 0 else 'green' for x in top_features['Coefficient']]
axes[1, 1].barh(range(len(top_features)), top_features['Coefficient'], color=colors, alpha=0.7)
axes[1, 1].set_yticks(range(len(top_features)))
axes[1, 1].set_yticklabels(top_features['Feature'])
axes[1, 1].set_xlabel('Coefficient Value')
axes[1, 1].set_title('Top 15 Feature Coefficients\n(Red=Decreases Delay | Green=Increases Delay)')
axes[1, 1].axvline(x=0, color='black', linestyle='--', linewidth=0.8)
axes[1, 1].invert_yaxis()

plt.tight_layout()
plt.show()

# --- Step 10: Model Comparison Summary ---
print("\n" + "="*60)
print("MODEL SUMMARY:")
print("="*60)
print(f"✓ Training time: {training_time:.2f} seconds")
print(f"✓ Catching {recall_delayed*100:.1f}% of delays")
print(f"✓ {precision_delayed*100:.1f}% of delay predictions are accurate")
print(f"✓ Overall accuracy: {accuracy_score(y_test, y_pred_log)*100:.1f}%")
print(f"✓ ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.4f}")
print("\nModel Characteristics:")
print("• Fast training and prediction")
print("• Memory efficient")
print("• Good baseline for comparison")
print("• Interpretable coefficients")
print("="*60)

"""# Random Forest"""

import time
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, roc_curve
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

print("="*60)
print("RANDOM FOREST FOR FLIGHT DELAY PREDICTION")
print("="*60)

# --- Step 1: Check class distribution ---
class_counts = y_train.value_counts()
print(f"\nClass distribution in training set:")
print(f"Class 0 (on-time): {class_counts[0]:,}")
print(f"Class 1 (delayed): {class_counts[1]:,}")
print(f"Imbalance ratio: {class_counts[0]/class_counts[1]:.2f}:1")
print("="*60)

# --- Step 2: Train Random Forest ---
print("\nTraining Random Forest model...")
print("Note: This may take a few minutes due to dataset size...")
start_time = time.time()

rf_model = RandomForestClassifier(
    n_estimators=100,              # Number of trees (balanced for speed/performance)
    max_depth=15,                  # Maximum depth of trees
    min_samples_split=20,          # Minimum samples to split node
    min_samples_leaf=10,           # Minimum samples in leaf node
    max_features='sqrt',           # Number of features per split
    class_weight='balanced',       # Handles class imbalance
    n_jobs=-1,                     # Use all CPU cores
    random_state=42,
    verbose=1,                     # Show progress
    bootstrap=True,                # Bootstrap sampling
    max_samples=0.8                # Use 80% of data per tree (speeds up training)
)

rf_model.fit(X_train, y_train)

end_time = time.time()
training_time = end_time - start_time
print(f"\n✓ Training completed in {training_time:.2f} seconds ({training_time/60:.2f} minutes)")
print("="*60)

# --- Step 3: Get prediction probabilities ---
print("\nGenerating predictions...")
y_pred_proba = rf_model.predict_proba(X_test)[:, 1]

# --- Step 4: Find optimal threshold ---
thresholds = np.arange(0.3, 0.6, 0.05)
best_threshold = 0.5
best_f1 = 0

print("\nTesting different prediction thresholds:")
print(f"{'Threshold':<12} {'Precision':<12} {'Recall':<12} {'F1-Score':<12}")
print("-" * 50)

for threshold in thresholds:
    y_pred_temp = (y_pred_proba >= threshold).astype(int)
    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_temp).ravel()

    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

    print(f"{threshold:.2f}         {precision:.4f}       {recall:.4f}       {f1:.4f}")

    if f1 > best_f1:
        best_f1 = f1
        best_threshold = threshold

print(f"\n✓ Best threshold: {best_threshold:.2f} (F1-Score: {best_f1:.4f})")
print("="*60)

# --- Step 5: Make final predictions ---
y_pred_rf = (y_pred_proba >= best_threshold).astype(int)

# --- Step 6: Evaluation Metrics ---
print("\nFINAL MODEL PERFORMANCE:")
print("="*60)
print(f"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}")
print(f"ROC-AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}")

precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)
pr_auc = auc(recall, precision)
print(f"Precision-Recall AUC: {pr_auc:.4f}")

print("\nClassification Report:")
print(classification_report(y_test, y_pred_rf))

# Confusion matrix
cm_rf = confusion_matrix(y_test, y_pred_rf)
tn, fp, fn, tp = cm_rf.ravel()

# Detailed metrics
recall_delayed = tp / (tp + fn)
precision_delayed = tp / (tp + fp) if (tp + fp) > 0 else 0
f1_delayed = 2 * (precision_delayed * recall_delayed) / (precision_delayed + recall_delayed)

print("\nDETAILED METRICS FOR DELAYED FLIGHTS (Class 1):")
print("="*60)
print(f"True Positives (correctly predicted delays): {tp:,}")
print(f"False Positives (false alarms): {fp:,}")
print(f"False Negatives (missed delays): {fn:,}")
print(f"True Negatives (correctly predicted on-time): {tn:,}")
print(f"\nRecall: {recall_delayed:.4f} → Catching {recall_delayed*100:.2f}% of actual delays")
print(f"Precision: {precision_delayed:.4f} → {precision_delayed*100:.2f}% of delay predictions are correct")
print(f"F1-Score: {f1_delayed:.4f}")

# --- Step 7: Feature Importance ---
feature_importance = pd.DataFrame({
    'Feature': X.columns,
    'Importance': rf_model.feature_importances_
}).sort_values('Importance', ascending=False)

print("\nTop 10 Most Important Features:")
print("="*60)
for idx, row in feature_importance.head(10).iterrows():
    print(f"{row['Feature']:<25} {row['Importance']:.4f}")

# --- Step 8: Visualizations ---
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# Confusion Matrix
sns.heatmap(cm_rf, annot=True, fmt=",d", cmap="Greens", ax=axes[0, 0])
axes[0, 0].set_title(f"Confusion Matrix (Threshold: {best_threshold:.2f})")
axes[0, 0].set_xlabel("Predicted")
axes[0, 0].set_ylabel("Actual")

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
roc_auc = roc_auc_score(y_test, y_pred_proba)
axes[0, 1].plot(fpr, tpr, color='darkgreen', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
axes[0, 1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')
axes[0, 1].set_xlabel('False Positive Rate')
axes[0, 1].set_ylabel('True Positive Rate')
axes[0, 1].set_title('ROC Curve')
axes[0, 1].legend(loc="lower right")
axes[0, 1].grid(True, alpha=0.3)

# Precision-Recall Curve
precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_proba)
axes[1, 0].plot(recall_curve, precision_curve, color='forestgreen', lw=2, label=f'PR curve (AUC = {pr_auc:.2f})')
axes[1, 0].set_xlabel('Recall')
axes[1, 0].set_ylabel('Precision')
axes[1, 0].set_title('Precision-Recall Curve')
axes[1, 0].legend(loc="lower left")
axes[1, 0].grid(True, alpha=0.3)

# Feature Importance (Top 15)
top_features = feature_importance.head(15)
axes[1, 1].barh(range(len(top_features)), top_features['Importance'], color='lightgreen', alpha=0.8)
axes[1, 1].set_yticks(range(len(top_features)))
axes[1, 1].set_yticklabels(top_features['Feature'])
axes[1, 1].set_xlabel('Importance Score')
axes[1, 1].set_title('Top 15 Most Important Features')
axes[1, 1].invert_yaxis()

plt.tight_layout()
plt.show()

# --- Step 9: Model Summary ---
print("\n" + "="*60)
print("MODEL SUMMARY:")
print("="*60)
print(f"✓ Training time: {training_time:.2f} seconds ({training_time/60:.2f} minutes)")
print(f"✓ Catching {recall_delayed*100:.1f}% of delays")
print(f"✓ {precision_delayed*100:.1f}% of delay predictions are accurate")
print(f"✓ Overall accuracy: {accuracy_score(y_test, y_pred_rf)*100:.1f}%")
print(f"✓ ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.4f}")
print(f"✓ Number of trees: {rf_model.n_estimators}")
print("\nModel Characteristics:")
print("• Robust to overfitting (ensemble method)")
print("• Handles non-linear relationships well")
print("• Good feature importance interpretation")
print("• Parallel processing for faster training")
print("• Works well with imbalanced data")
print("="*60)

# --- Step 10: Comparison with Other Models (Optional) ---
print("\n" + "="*60)
print("QUICK COMPARISON:")
print("="*60)
print("Random Forest vs Other Models:")
print("• More robust than single decision trees")
print("• Often performs between Logistic Regression and XGBoost")
print("• Less prone to overfitting than deep trees")
print("• Better interpretability than XGBoost")
print("• May be slower than XGBoost on very large datasets")
print("="*60)

print(dataset['AIRLINE_CODE'].unique())

print(dataset['ORIGIN'].unique()[:10])

print(dataset.columns.tolist())

import pickle
import pandas as pd
from google.colab import files

print("="*60)
print("EXPORTING MODELS AND DATA")
print("="*60)

# ============================================
# 1. SAVE ALL THREE MODELS
# ============================================
print("\n[1/5] Saving models...")

# XGBoost
with open('xgboost_model.pkl', 'wb') as f:
    pickle.dump(xgb_model, f)
print("✓ XGBoost saved")

# Random Forest
with open('random_forest_model.pkl', 'wb') as f:
    pickle.dump(rf_model, f)
print("✓ Random Forest saved")

# Logistic Regression (need to save model AND scaler together!)
with open('logistic_model.pkl', 'wb') as f:
    pickle.dump({'model': log_model, 'scaler': scaler}, f)
print("✓ Logistic Regression + Scaler saved")

# ============================================
# 2. CREATE AIRLINE MAPPING
# ============================================
print("\n[2/5] Creating airline mapping...")

# Airline codes and names mapping
airline_mapping = {
    14: 'Southwest Airlines',
    4: 'Alaska Airlines',
    10: 'JetBlue Airways',
    15: 'Spirit Airlines',
    1: 'American Airlines',
    17: 'United Airlines',
    2: 'Delta Air Lines',
    3: 'Frontier Airlines',
    11: 'SkyWest Airlines',
    7: 'Endeavor Air',
    5: 'Allegiant Air',
    12: 'PSA Airlines',
    0: 'Envoy Air',
    9: 'Hawaiian Airlines',
    6: 'Republic Airways',
    16: 'Mesa Airlines',
    13: 'Horizon Air',
    8: 'GoJet Airlines'
}

airlines_df = pd.DataFrame(list(airline_mapping.items()),
                          columns=['AIRLINE_CODE', 'AIRLINE_NAME'])
airlines_df = airlines_df.sort_values('AIRLINE_CODE')
airlines_df.to_csv('airlines.csv', index=False)
print(f"✓ Saved {len(airlines_df)} airlines")

# ============================================
# 3. CREATE AIRPORT MAPPING
# ============================================
print("\n[3/5] Creating airport mapping...")

# Get all unique airports from both ORIGIN and DEST
all_airports = pd.concat([
    dataset[['ORIGIN']].rename(columns={'ORIGIN': 'AIRPORT_CODE'}),
    dataset[['DEST']].rename(columns={'DEST': 'AIRPORT_CODE'})
]).drop_duplicates().sort_values('AIRPORT_CODE')

# Common US airport names (you can customize this)
airport_names = {
    131: 'ATL - Atlanta', 247: 'LAX - Los Angeles', 99: 'DEN - Denver',
    223: 'IAH - Houston', 93: 'DFW - Dallas/Fort Worth', 96: 'DTW - Detroit',
    167: 'JFK - New York', 174: 'LAS - Las Vegas', 323: 'PHX - Phoenix',
    23: 'BOS - Boston', # Add more as needed
}

all_airports['AIRPORT_NAME'] = all_airports['AIRPORT_CODE'].map(
    lambda x: airport_names.get(x, f'Airport {x}')
)
all_airports.to_csv('airports.csv', index=False)
print(f"✓ Saved {len(all_airports)} airports")

# ============================================
# 4. SAVE FEATURE INFORMATION
# ============================================
print("\n[4/5] Saving feature information...")

# Feature names in exact order
feature_names = X.columns.tolist()
with open('feature_names.txt', 'w') as f:
    for feature in feature_names:
        f.write(f"{feature}\n")
print(f"✓ Saved {len(feature_names)} feature names")

# Feature statistics for validation
feature_stats = {
    'features': feature_names,
    'distance_min': float(dataset['DISTANCE'].min()),
    'distance_max': float(dataset['DISTANCE'].max()),
    'dep_hour_min': 0,
    'dep_hour_max': 23,
    'time_blocks': {
        'Early Morning (12am-6am)': 0,
        'Morning (6am-12pm)': 1,
        'Afternoon (12pm-6pm)': 2,
        'Evening (6pm-10pm)': 3,
        'Night (10pm-12am)': 4
    },
    'distance_categories': {
        'Short (0-500 mi)': 0,
        'Medium (500-1000 mi)': 1,
        'Long (1000-2000 mi)': 2,
        'Very Long (2000+ mi)': 3
    }
}

import json
with open('feature_info.json', 'w') as f:
    json.dump(feature_stats, f, indent=2)
print("✓ Saved feature statistics")

# ============================================
# 5. DOWNLOAD ALL FILES
# ============================================
print("\n[5/5] Downloading files to your computer...")

files.download('xgboost_model.pkl')
files.download('random_forest_model.pkl')
files.download('logistic_model.pkl')
files.download('airlines.csv')
files.download('airports.csv')
files.download('feature_names.txt')
files.download('feature_info.json')

print("\n" + "="*60)
print("EXPORT COMPLETE!")
print("="*60)
print("Check your Downloads folder for 7 files:")
print("1. xgboost_model.pkl")
print("2. random_forest_model.pkl")
print("3. logistic_model.pkl")
print("4. airlines.csv")
print("5. airports.csv")
print("6. feature_names.txt")
print("7. feature_info.json")
print("="*60)

from google.colab import files
import pandas as pd

# Get all unique airports
all_airports = pd.concat([
    dataset[['ORIGIN']].rename(columns={'ORIGIN': 'AIRPORT_CODE'}),
    dataset[['DEST']].rename(columns={'DEST': 'AIRPORT_CODE'})
]).drop_duplicates().sort_values('AIRPORT_CODE')

# Top 20 airport names mapping
airport_names = {
    23: 'BOS - Boston Logan',
    100: 'DEN - Denver',
    261: 'LAX - Los Angeles',
    99: 'DFW - Dallas/Fort Worth',
    77: 'CLT - Charlotte',
    201: 'HNL - Honolulu',
    276: 'LGA - New York LaGuardia',
    199: 'HOU - Houston Hobby',
    323: 'PHX - Phoenix',
    223: 'IAH - Houston Bush',
    108: 'EWR - Newark',
    174: 'LAS - Las Vegas',
    210: 'IAD - Washington Dulles',
    247: 'JFK - New York JFK',
    325: 'PHL - Philadelphia',
    49: 'BWI - Baltimore',
    96: 'DTW - Detroit',
    335: 'PDX - Portland',
    123: 'FLL - Fort Lauderdale',
    190: 'HKK - Hokkaido'
}

# Apply mapping (top 20 get real names, rest get generic)
all_airports['AIRPORT_NAME'] = all_airports['AIRPORT_CODE'].apply(
    lambda x: airport_names.get(x, f'Airport {x}')
)

# Save and download
all_airports.to_csv('airports_updated.csv', index=False)
print(f"Created file with {len(all_airports)} airports")
print("\nFirst 10 airports:")
print(all_airports.head(10))

files.download('airports_updated.csv')

# Show me your actual airline codes and their frequencies
airline_counts = dataset.groupby('AIRLINE_CODE').size().sort_values(ascending=False)
print(airline_counts)

from google.colab import files
import pandas as pd

# Check if you have airline/airport name columns
print("Available columns:", dataset.columns.tolist())

# If you have original name columns, export them
# Replace 'AIRLINE_NAME_COLUMN' with your actual column name
if 'OP_UNIQUE_CARRIER' in dataset.columns:  # Common airline name column
    airline_map = dataset[['AIRLINE_CODE', 'OP_UNIQUE_CARRIER']].drop_duplicates()
    airline_map.columns = ['AIRLINE_CODE', 'AIRLINE_NAME']
    airline_map.to_csv('airlines_with_names.csv', index=False)
    files.download('airlines_with_names.csv')
    print("✓ Airlines with names exported")

# For airports - if you have names
if 'ORIGIN_CITY_NAME' in dataset.columns:
    origin_map = dataset[['ORIGIN', 'ORIGIN_CITY_NAME']].drop_duplicates()
    dest_map = dataset[['DEST', 'DEST_CITY_NAME']].drop_duplicates()
    origin_map.columns = ['AIRPORT_CODE', 'AIRPORT_NAME']
    dest_map.columns = ['AIRPORT_CODE', 'AIRPORT_NAME']
    airport_map = pd.concat([origin_map, dest_map]).drop_duplicates()
    airport_map.to_csv('airports_with_names.csv', index=False)
    files.download('airports_with_names.csv')
    print("✓ Airports with names exported")

print(dataset['ORIGIN'].value_counts().head(20))

df1 = pd.read_csv('/content/drive/MyDrive/flights_sample_3m.csv')

df1.columns.tolist()

from google.colab import files
import pandas as pd

# Use ORIGIN_CITY and DEST_CITY to create airport mappings
origin_map = df1[['ORIGIN', 'ORIGIN_CITY']].drop_duplicates()
dest_map = df1[['DEST', 'DEST_CITY']].drop_duplicates()

origin_map.columns = ['AIRPORT_CODE', 'AIRPORT_NAME']
dest_map.columns = ['AIRPORT_CODE', 'AIRPORT_NAME']

# Combine and remove duplicates
airports_real = pd.concat([origin_map, dest_map]).drop_duplicates().sort_values('AIRPORT_CODE')

# Save and download
airports_real.to_csv('airports_real_names.csv', index=False)
print(f"Exported {len(airports_real)} airports with real city names")
print("\nFirst 20 airports:")
print(airports_real.head(20))

files.download('airports_real_names.csv')

# Export real airline names
airline_map = df1[['AIRLINE_CODE', 'AIRLINE']].drop_duplicates().sort_values('AIRLINE_CODE')
airline_map.columns = ['AIRLINE_CODE', 'AIRLINE_NAME']

airline_map.to_csv('airlines_real_names.csv', index=False)
print(f"\nExported {len(airline_map)} airlines with real names")
print(airline_map)

files.download('airlines_real_names.csv')

import pickle

# You should already have this from your training:
# label_encoders = {} dictionary with your encoders

# If you don't have it in memory anymore, you need to recreate it
# But first, let me give you code to export what you have

print("Exporting label encoders...")

# Create a clean dictionary with just the mappings we need
encoder_mappings = {}

for col_name, encoder in label_encoders.items():
    # Get the mapping: original_value -> encoded_number
    mapping = {original: encoded for encoded, original in enumerate(encoder.classes_)}
    encoder_mappings[col_name] = mapping
    print(f"\n{col_name}:")
    print(f"  Total unique values: {len(mapping)}")
    print(f"  Sample: {list(mapping.items())[:3]}")

# Save the encoders
with open('label_encoders.pkl', 'wb') as f:
    pickle.dump(encoder_mappings, f)

print("\n✓ Label encoders saved!")
print("\nNow download 'label_encoders.pkl' and put it in your 'models/' folder")

# Also create a readable JSON version for debugging
import json

# Convert to JSON-friendly format
json_encoders = {}
for key, mapping in encoder_mappings.items():
    json_encoders[key] = {str(k): int(v) for k, v in mapping.items()}

with open('label_encoders.json', 'w') as f:
    json.dump(json_encoders, f, indent=2)

print("✓ Also saved as JSON for easy viewing")

print("TIME_BLOCK mappings:")
for original, encoded in encoder_mappings['TIME_BLOCK'].items():
    print(f"  '{original}' -> {encoded}")

print("\nDISTANCE_CAT mappings:")
for original, encoded in encoder_mappings['DISTANCE_CAT'].items():
    print(f"  '{original}' -> {encoded}")

from google.colab import files

# Download the pickle file
files.download('label_encoders.pkl')

# Also download JSON for reference
files.download('label_encoders.json')

# Get unique flight numbers per airline
flight_numbers_by_airline = dataset.groupby('AIRLINE_CODE')['FL_NUMBER'].unique()

for airline, flights in flight_numbers_by_airline.items():
    print(f"{airline}: {len(flights)} flights")
    print(f"  Sample: {sorted(flights)[:10]}")
    print()

import json
import numpy as np

# Get the reverse mapping from encoded number to actual airline code
airline_encoder = label_encoders['AIRLINE_CODE']
# Corrected: Access classes_ attribute and create the reverse mapping
reverse_airline_map = {idx: code for idx, code in enumerate(airline_encoder.classes_)}

# Create dictionary mapping ACTUAL airline codes to their flight numbers
flight_numbers_map = {}

for encoded_airline in dataset['AIRLINE_CODE'].unique():
    # Get the actual airline code (e.g., "AA", "DL")
    actual_airline_code = reverse_airline_map[encoded_airline]

    # Get flight numbers for this airline
    flights = dataset[dataset['AIRLINE_CODE'] == encoded_airline]['FL_NUMBER'].unique()
    flights = sorted([int(f) for f in flights])

    flight_numbers_map[actual_airline_code] = flights

# Save to JSON
with open('flight_numbers.json', 'w') as f:
    json.dump(flight_numbers_map, f, indent=2)

print("Flight numbers exported!")
print(f"Total airlines: {len(flight_numbers_map)}")

# Show sample with actual airline codes
for code, flights in list(flight_numbers_map.items())[:5]:
    print(f"{code}: {len(flights)} flights (range: {min(flights)}-{max(flights)})")

# Download the file
from google.colab import files
files.download('flight_numbers.json')

"""# Exporting model performance"""

import json
import pickle
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Calculate metrics for each model (assuming you have y_test and predictions)
metrics = {
    "XGBoost": {
        "accuracy": accuracy_score(y_test, y_pred_xgb),
        "precision": precision_score(y_test, y_pred_xgb),
        "recall": recall_score(y_test, y_pred_xgb),
        "f1_score": f1_score(y_test, y_pred_xgb)
    },
    "Logistic_Regression": {
        "accuracy": accuracy_score(y_test, y_pred_log),
        "precision": precision_score(y_test, y_pred_log),
        "recall": recall_score(y_test, y_pred_log),
        "f1_score": f1_score(y_test, y_pred_log)
    }
}

# Save metrics
with open('model_metrics.json', 'w') as f:
    json.dump(metrics, f, indent=2)

# Export feature importance from XGBoost
feature_importance = {
    'features': X.columns.tolist(),
    'importance': xgb_model.feature_importances_.tolist()
}

with open('feature_importance.json', 'w') as f:
    json.dump(feature_importance, f, indent=2)

print("Metrics saved!")
print(f"XGBoost Accuracy: {metrics['XGBoost']['accuracy']:.2%}")
print(f"Logistic Accuracy: {metrics['Logistic_Regression']['accuracy']:.2%}")

# Download files
from google.colab import files
files.download('model_metrics.json')
files.download('feature_importance.json')

# Check if you have the required variables
print("Checking variables...")

# Check if you have test predictions
try:
    print(f"✓ y_test exists: {len(y_test)} samples")
except:
    print("✗ y_test not found")

try:
    print(f"✓ xgb_pred exists: {len(xgb_pred)} predictions")
except:
    print("✗ xgb_pred not found - need to create it")

try:
    print(f"✓ log_pred exists: {len(log_pred)} predictions")
except:
    print("✗ log_pred not found - need to create it")

# Make predictions on test set
print("Creating predictions...")

# XGBoost predictions
xgb_pred = xgb_model.predict(X_test)
print(f"✓ XGBoost predictions created: {len(xgb_pred)}")

# Load the logistic model if not already in memory
import pickle
try:
    with open('logistic_model.pkl', 'rb') as f:
        log_data = pickle.load(f)
    print("✓ Logistic model loaded")
except FileNotFoundError:
    print("Error: logistic_model.pkl not found. Please ensure the model was saved correctly.")
    # You might want to add a way to handle this error,
    # perhaps by training the model again if needed.
    # For now, we'll stop here if the file isn't found.
    raise

# Logistic Regression predictions
log_pred = log_data['model'].predict(log_data['scaler'].transform(X_test))
print(f"✓ Logistic predictions created: {len(log_pred)}")

# Now export metrics
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import json

metrics = {
    "XGBoost": {
        "accuracy": float(accuracy_score(y_test, xgb_pred)),
        "precision": float(precision_score(y_test, xgb_pred)),
        "recall": float(recall_score(y_test, xgb_pred)),
        "f1_score": float(f1_score(y_test, xgb_pred))
    },
    "Logistic_Regression": {
        "accuracy": float(accuracy_score(y_test, log_pred)),
        "precision": float(precision_score(y_test, log_pred)),
        "recall": float(recall_score(y_test, log_pred)),
        "f1_score": float(f1_score(y_test, log_pred))
    }
}

# Save
with open('model_metrics.json', 'w') as f:
    json.dump(metrics, f, indent=2)

# Verify content
print("\n" + "="*50)
print("METRICS SAVED:")
print("="*50)
for model, scores in metrics.items():
    print(f"\n{model}:")
    for metric, value in scores.items():
        print(f"  {metric}: {value:.4f}")

# Export feature importance
feature_importance = {
    'features': X_test.columns.tolist(),
    'importance': xgb_model.feature_importances_.tolist()
}

with open('feature_importance.json', 'w') as f:
    json.dump(feature_importance, f, indent=2)

print("\n✓ Both files created successfully!")

# Download
from google.colab import files
files.download('model_metrics.json')
files.download('feature_importance.json')

# Load the logistic model if not already in memory
import pickle

with open('logistic_model.pkl', 'rb') as f:
    log_data = pickle.load(f)

print("✓ Logistic model loaded")

# Now create predictions
log_pred = log_data['model'].predict(log_data['scaler'].transform(X_test))
print(f"✓ Logistic predictions created: {len(log_pred)}")

# Export metrics
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import json

metrics = {
    "XGBoost": {
        "accuracy": float(accuracy_score(y_test, xgb_pred)),
        "precision": float(precision_score(y_test, xgb_pred)),
        "recall": float(recall_score(y_test, xgb_pred)),
        "f1_score": float(f1_score(y_test, xgb_pred))
    },
    "Logistic_Regression": {
        "accuracy": float(accuracy_score(y_test, log_pred)),
        "precision": float(precision_score(y_test, log_pred)),
        "recall": float(recall_score(y_test, log_pred)),
        "f1_score": float(f1_score(y_test, log_pred))
    }
}

# Save files
with open('model_metrics.json', 'w') as f:
    json.dump(metrics, f, indent=2)

feature_importance = {
    'features': X_test.columns.tolist(),
    'importance': xgb_model.feature_importances_.tolist()
}

with open('feature_importance.json', 'w') as f:
    json.dump(feature_importance, f, indent=2)

print("\n" + "="*50)
print("METRICS:")
print("="*50)
for model, scores in metrics.items():
    print(f"\n{model}:")
    for metric, value in scores.items():
        print(f"  {metric}: {value*100:.2f}%")

# Download both files
from google.colab import files
files.download('model_metrics.json')
files.download('feature_importance.json')

import pickle

# Make sure you have both the trained model and fitted scaler
log_export = {
    'model': log_model,  # Your trained LogisticRegression model
    'scaler': scaler     # Your fitted StandardScaler
}

# Save it
with open('logistic_model.pkl', 'wb') as f:
    pickle.dump(log_export, f)

# Test it works
print("Testing export...")
with open('logistic_model.pkl', 'rb') as f:
    test_load = pickle.load(f)

print(f"✓ Model type: {type(test_load['model'])}")
print(f"✓ Scaler type: {type(test_load['scaler'])}")
print(f"✓ Scaler mean shape: {test_load['scaler'].mean_.shape}")
print(f"✓ Scaler scale shape: {test_load['scaler'].scale_.shape}")

# Make a test prediction to verify
test_sample = X_test.iloc[[0]]
test_scaled = test_load['scaler'].transform(test_sample)
test_pred = test_load['model'].predict(test_scaled)
test_proba = test_load['model'].predict_proba(test_scaled)

print(f"\nTest prediction: {test_pred[0]}")
print(f"Test probabilities: {test_proba[0]}")

# Download
from google.colab import files
files.download('logistic_model.pkl')

# Load the original data again (fresh copy)
original_data = pd.read_csv('/content/drive/MyDrive/flights_sample_3m.csv')

# Create distance lookup from ORIGINAL data
distance_lookup = original_data[['ORIGIN', 'DEST', 'DISTANCE']].drop_duplicates()

# Get average distance for each route
distance_lookup = distance_lookup.groupby(['ORIGIN', 'DEST'])['DISTANCE'].mean().reset_index()

# Round to nearest mile
distance_lookup['DISTANCE'] = distance_lookup['DISTANCE'].round(0).astype(int)

print(f"Exported {len(distance_lookup)} unique routes")
print("\nSample routes:")
print(distance_lookup.head(20))
print(f"\nDistance range: {distance_lookup['DISTANCE'].min()} - {distance_lookup['DISTANCE'].max()} miles")

# Save to CSV
distance_lookup.to_csv('distance_lookup.csv', index=False)

print("\n✓ distance_lookup.csv created!")
print("Download this file and put it in your data/ folder")

# Load the exported model
import pickle
with open('logistic_model.pkl', 'rb') as f:
    log_data = pickle.load(f)

# Check scaler properties
print("Scaler Info:")
print(f"Number of features: {len(log_data['scaler'].mean_)}")
print(f"Scaler mean (first 5): {log_data['scaler'].mean_[:5]}")
print(f"Scaler scale (first 5): {log_data['scaler'].scale_[:5]}")

# Check model coefficients
print(f"\nModel coefficients (first 5): {log_data['model'].coef_[0][:5]}")
print(f"Model intercept: {log_data['model'].intercept_[0]}")

# Test with a KNOWN delayed flight from training data
delayed_sample = X_test[y_test == 1].iloc[[0]]
print(f"\nTesting with a delayed flight:")
print(f"Original features:\n{delayed_sample}")

# Scale it
scaled_sample = log_data['scaler'].transform(delayed_sample)
print(f"\nScaled features (first 5): {scaled_sample[0][:5]}")

# Predict
pred = log_data['model'].predict(scaled_sample)
proba = log_data['model'].predict_proba(scaled_sample)

print(f"\nPrediction: {pred[0]} (0=on-time, 1=delayed)")
print(f"Probabilities: [on-time={proba[0][0]:.4f}, delayed={proba[0][1]:.4f}]")

# Test with on-time flight
ontime_sample = X_test[y_test == 0].iloc[[0]]
scaled_ontime = log_data['scaler'].transform(ontime_sample)
pred_ontime = log_data['model'].predict(scaled_ontime)
proba_ontime = log_data['model'].predict_proba(scaled_ontime)

print(f"\nOn-time flight prediction: {pred_ontime[0]}")
print(f"Probabilities: [on-time={proba_ontime[0][0]:.4f}, delayed={proba_ontime[0][1]:.4f}]")

# Check what your ORIGINAL X_train looked like
print("X_train sample (first row):")
print(X_train.iloc[0])
print("\nData types:")
print(X_train.dtypes)

# Check the range of time features in training data
print("CRS_DEP_TIME range:", X_train['CRS_DEP_TIME'].min(), "to", X_train['CRS_DEP_TIME'].max())
print("CRS_ARR_TIME range:", X_train['CRS_ARR_TIME'].min(), "to", X_train['CRS_ARR_TIME'].max())
print("DEP_HOUR range:", X_train['DEP_HOUR'].min(), "to", X_train['DEP_HOUR'].max())
print("\nSample values:")
print(X_train[['CRS_DEP_TIME', 'CRS_ARR_TIME', 'DEP_HOUR']].head())

# Start fresh - make sure your X_train and X_test are properly prepared
print("Original X_train sample:")
print(X_train.iloc[0])

# IMPORTANT: Make sure categorical features are encoded but NOTHING is normalized yet
# Your X_train should have:
# - Encoded integers for AIRLINE_CODE, ORIGIN, DEST, TIME_BLOCK, DISTANCE_CAT
# - Raw numbers for everything else (CRS_DEP_TIME in HHMM, distance in miles, etc.)

# Now apply StandardScaler ONLY to the training data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train logistic regression
log_model = LogisticRegression(
    class_weight='balanced',
    max_iter=1000,
    solver='saga',
    penalty='l2',
    C=1.0,
    n_jobs=-1,
    random_state=42
)

log_model.fit(X_train_scaled, y_train)

# Export
log_export = {
    'model': log_model,
    'scaler': scaler
}

with open('logistic_model.pkl', 'wb') as f:
    pickle.dump(log_export, f)

# Download
from google.colab import files
files.download('logistic_model.pkl')

print(dataset[['CRS_DEP_TIME', 'CRS_ARR_TIME', 'DEP_HOUR']].head())